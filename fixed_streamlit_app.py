# -*- coding: utf-8 -*-
"""Fixed Streamlit App

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FCcaeVOyeCtFrGig0tRQ5GsYXEWX03US
"""

# -*- coding: utf-8 -*-
"""Copy of EEP 105 Final Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V5CFEmIkMn4EleoCwmvKwguHEDa-u1kk
"""


#Import packages
import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from scipy import stats
from lets_plot import *
from plotnine import (
    ggplot,
    aes,
    geom_line,
    labs,
    scale_x_continuous,
    geom_text_repel,
    geom_tile,
    facet_grid,
    facet_wrap,
    geom_point,
    geom_smooth,
    ggsize,
    ggsave,
    scale_color_manual,
    scale_fill_viridis,
    gggrid
)
from plotnine.themes.theme_seaborn import theme_seaborn
from plotnine.themes import theme, element_rect, element_text

LetsPlot.setup_html()

st.title("Group Project: Dashboard")
st.write("Amanda Yun + Chloe Choi's Dashboard")

df_co2 = pd.read_csv("https://raw.githubusercontent.com/AmandaYun5/EEP-105-Final-Project-Data/refs/heads/main/yearly_co2_emissions_1000_tonnes.csv")
df_gdp = pd.read_csv("https://raw.githubusercontent.com/AmandaYun5/EEP-105-Final-Project-Data/refs/heads/main/gdp_per_capita_yearly_growth.csv")
df_en = pd.read_csv("https://raw.githubusercontent.com/AmandaYun5/EEP-105-Final-Project-Data/refs/heads/main/energy_use_per_person.csv")
df_nd = pd.read_csv("https://raw.githubusercontent.com/AmandaYun5/EEP-105-Final-Project-Data/refs/heads/main/sk_natural_disaster_data.csv")
df_temp = pd.read_csv("https://raw.githubusercontent.com/AmandaYun5/EEP-105-Final-Project-Data/refs/heads/main/sk_temp_data.csv")

#Yearly CO2 emissions by country (1751-2014):
df_co2.head()

#GDP per capita in terms of yearly percentage growth per capita by country (1801-2019):
df_gdp.head()

#Energy use per person in terms of kg of oil equivalents per capita by country (1990-2023):
df_en.head()

#SK data on natural disasters (1977-2025):
df_nd.head()

#SK data on temperature (1895-2019):
df_temp.head()

"""# Data Wrangling"""

# there are 192 rows of different countries and their CO2 emissoins values from 1751-2014
#some countries have missing data
#code below shows the years in our data
print(df_co2.columns)
column_names_list = list(df_co2.columns)
print(column_names_list)

#use .melt() to change data from wide to long, this makes the data a little more tidy
# changes the year columns into a single column called year with its corresponding values
# grabbing a random sample from the CO2 emissions data

CO2_emissions_long = pd.melt(
    df_co2,
    id_vars=['country'],
    var_name='Year',
    value_name='Emissions'
)

random_sample = CO2_emissions_long.sample(n=6, random_state = 123)
print (random_sample)
CO2_emissions_long

# clean and tidy the CO2 data further
df_co2_c = (
    CO2_emissions_long
    .rename(columns={'country': 'Country'})
    .assign(Year=lambda df: pd.to_numeric(df['Year']),
            Label="CO2 Emissions (Metric Tons)")
    .dropna(subset=['Emissions']) # Add this line to drop rows where 'Emissions' is NaN
)

print(df_co2_c.head())

#Yearly Growth in GDP Per Capita (GDP_PC) Data Wrangling
# checking number of rows in the GDP_pc data frame
num_rows = len(df_gdp)
print(f'Number of rows: {num_rows}')
# shows 194 rows as opposed to 50688

#checking number of columns:
num_cols = len(df_gdp.columns)
print(f'Number of columns: {num_cols}')

# there's 220 country columns and a set of columns corresponding to different years
# use .melt() to change data from wide to long, this makes the data a little more tidy changes the year columns into a single column called year with its corresponding values
df_gdp_long = pd.melt(
    df_gdp,
    id_vars=['country'],
    var_name='Year',
    value_name='GDP per capita'
)

# grabbing a random sample from the GDP per capita data

random_sample = df_gdp_long.sample(n=6, random_state = 123)
print (random_sample)

# clean and tidy the GDP_pc data further
df_gdp_c = (
    df_gdp_long
    .rename(columns={'country': 'Country'})
    .assign(Year=lambda df: pd.to_numeric(df['Year']),
            Label="GDP per Capita Yearly Growth")
     .dropna(subset=['GDP per capita']) # Add this line to drop rows where 'GDP' is NaN
)

print(df_gdp_c.head())

# cleaning the Data for Energy Use per person (E_use_pp)

# use .melt() to change data from wide to long, this makes the data a little more tidy

# changes the year columns into a single column called year with its corresponding values

df_en_long = pd.melt(
    df_en,
    id_vars=['country'],
    var_name='Year',
    value_name='Energy Use PP'
)

# grabbing a random sample from the Energy use per person data

random_sample = df_en_long.sample(n=6, random_state = 123)
print (random_sample)

# clean the E_use_pp data further:
# Convert Year to an integer
# Add a new 'Label' column
# Rename the energy use column
df_en_c = (
    df_en_long
    .rename(columns={'country': 'Country'})
    .assign(
        Year=lambda df: df['Year'].astype(int),
        Label="Energy Use (kg, oil-eq./capita)"
    )
    .rename(columns={'energy_use': 'Energy'})
        .dropna(subset=['Energy Use PP']) # Add this line to drop rows where 'Energy' is NaN
)
df_en_c

# setting seed for reproducibility, ensures that the random sample is the same every time you run the code.

np.random.seed(123)
#  grabbing 3 random rows from the Data frame
energy_use_sample = df_en_c.sample(n=3).reset_index(drop=True)
# showing the sample
print(energy_use_sample)

# checking unique values in Country column, showing different countries, picked first 10 for shorter demonstration

unique_countries = df_en_c['Country'].unique()
print("\nUnique countries in the dataset (first 10):")
print(unique_countries[:10])

# showing number of unique countries
unique_countries = df_en_c['Country'].unique()
print(f"\nTotal number of unique countries: {len(unique_countries)}")

#Now we're going to look at the SK specific data
# These data sets only gave us info for the SK

# Disasters Data Wrangling
# showing the data
df_nd

#Select only "Year" and "Disasters" columns
df_nd = df_nd.loc[:,["Start Year", "Disaster Type"]]

#Count number of disasters per year and alter the "Value" column
df_nd = df_nd.groupby("Start Year").agg("Disaster Type").count().reset_index()

#Add "Country", "Indicator", "Label" columns to show that data are from the U.S. disasters dataset
df_nd["Country"] = "South Korea"
df_nd["Indicator"] = "Disasters"
df_nd["Label"] = "Number of Disasters"

#Rename "Disaster" column to "Number of Disasters"
df_nd = df_nd.rename(columns = {"Start Year": "Year", "Disaster Type":"Value"})
df_nd_c = df_nd[["Country", "Year", "Indicator", "Value", "Label"]]
df_nd_c

#Pivot temperature data to long form
df_no_identifiers = df_temp.drop(columns=['code', 'name'])
df_temp_long = df_no_identifiers.melt(var_name='year', value_name='temperature')

#Add columns "Country," "Indicator," "Label"
df_temp_long["Country"] = "South Korea"
df_temp_long["Indicator"] = "Temperature"
df_temp_long["Label"] = "Temperature (Celsius)"

#Rename columns, select first four digits of year values (and change to numeric)
df_temp_long = df_temp_long.rename(columns = {"year":"Year", "temperature":"Value"})
df_temp_long["Year"] = df_temp_long["Year"].str[:4].astype("int64")
df_temp_c = df_temp_long[["Country", "Year", "Indicator", "Value", "Label"]]
df_temp_c

# Joining the data
df_co2_c.describe()
df_gdp_c.describe()
df_en_c.describe()
df_nd_c.describe()
df_temp_c.describe()


#Why do we need this right here? - oh just bc like i wanted to see it lol

# now we combine data sets
# merge CO2 Emissions and GDP growth per capita

data_wide = pd.merge(
    left= df_co2_c,
    right= df_gdp_c,
    on=['Country', 'Year', 'Label'],
    how='outer'
)

# then merge with Energy use per person
data_wide = pd.merge(
    left=data_wide,
    right= df_en_c,
    on=['Country', 'Year', 'Label'],
    how='outer'
)

data_wide

t = data_wide.query("Country == 'Germany'")
t.query("Year == 1862")

#  set random seed for reproducibility
np.random.seed(123)
print(data_wide.sample(n=3))

# reorder the columns for aesthetic preferences
new_column_order = [
    'Country',
    'Year',
    'Emissions',
    'GDP per capita',
    'Energy Use PP',
    'Label'
]
data_wide = data_wide[new_column_order]
np.random.seed(123)
print(data_wide.sample(n=3))

#this seems repetitive since I think the columns were already in this order
data_wide

j = data_wide.query("Country == 'Germany'")
j.query("Year ==1862")

# make long version of the data and create new variable called Indicator to indicate where the data set came from
data_long = data_wide.melt(
    id_vars=['Country', 'Year'],
    var_name='Indicator',
    value_vars=['Emissions', 'GDP per capita', 'Energy Use PP'],
    value_name = "Value"
)
data_long

#add label column afterward (including label with id_vars was making th elabels and indicator columns misalign for some values)
label_map = {
    'Emissions': 'CO2 Emissions (Metric Tons)',
    'GDP per capita': 'GDP per Capita Yearly Growth',
    'Energy Use PP': 'Energy Use (kg, oil-eq./capita)'
}
data_long['Label'] = data_long['Indicator'].map(label_map)
data_long

i = data_long.query("Country == 'Germany'")
i.query("Year ==1862")

# combine this with the US Data about Disasters and Temperature
# concat automatically handles columns that don't match by filling them with NaN just in case
# convering 'Country' column to a categorical data type in pandas
data_long = pd.concat([data_long, df_nd_c, df_temp_c])
data_long['Country'] = data_long['Country'].astype('category')
data_long = data_long.dropna()
print(data_long)
data_long

h = data_long.query("Country == 'Germany'")
h.query("Year ==1862")

# show first and last 6 rows of the combined data set
print(data_long.head(6))
print(data_long.tail(6))

# drop rows that have at least 1 NaN value
data_long_with_miss = data_long.sort_values(by='Country').reset_index(drop=True)
Final_df = data_long.dropna(subset=['Value']).sort_values(by='Country').reset_index(drop=True)
print(Final_df)
Final_df

g = Final_df.query("Country == 'Germany'")
g.query("Year ==1862")

# create a new variable called region that will indicate if Data ifro m the SK or a different country based on the Country variable
# ex: if country variable is US then new variable's value will the SK, but if the Country variable isn't equal to SK then it will be "Rest of the World"
data_long['Region'] = np.where(
    data_long['Country'] == 'South Korea',
    'South Korea',
    'Rest of the World'
)
Final_df = data_long.sort_values(by='Country')

print(Final_df)
Final_df

d = Final_df.query("Country == 'Germany'")
d.query("Year ==1862")

"""# Data Visualization"""

#Filter table to include only CO2 emissions data in order to plot emissions over time
#Sum emissions data across countries to get total emissons per year
df_co2_plot_agg = Final_df.query(
    "Indicator == 'Emissions'").groupby("Year", as_index = False)[["Value"]].sum()
df_co2_plot_agg

#Plot total CO2 emissions over time with ggplot

co2_plot = (ggplot(data = df_co2_plot_agg,
                  mapping = aes(x="Year", y="Value")
                 ) +
            geom_line(size = 1.5) +
            scale_x_continuous(format = "d", breaks = np.arange(1700, 2100, 100)) +
            labs(title = "World CO2 Emissions per Year (1751-2014)",
                y="Emissions (Metric Tonnes)",
                caption = "Limited to reporting Countries")+
            ggsize(600, 400)
               )
#st.pyplot(ggplot.draw(co2_plot)) # This line was already present
st.subheader("Total CO2 Emissions Over Time")
st.dataframe(df_co2_plot_agg.head())

#Plot CO2 emissions by country
df_co2_plot_country = Final_df.query("Indicator == 'Emissions'")

co2_plot_by_country = (ggplot(data = df_co2_plot_country,
                  mapping = aes(x="Year", y="Value", group= "Country")
                 ) +
                geom_line(alpha = 0.4) +
                scale_x_continuous(format = "d", breaks = np.arange(1700, 2100, 100)) +
                labs(title = "Country CO2 Emissions per Year (1751-2014)",
                y="Emissions (Metric Tonnes)",
                caption = "Limited to Reporting Countries")
                      )

# This line was missing, so the plot was not drawn
st.pyplot(ggplot.draw(co2_plot))

#Add another layer to highlight the SK line in blue
df_co2_plot_us = df_co2_plot_country.query("Country =='South Korea'")
co2_plot_by_country = co2_plot_by_country + geom_line(
                           data=df_co2_plot_us, mapping = aes(x="Year", y="Value", color = "Country")) + scale_color_manual(values = ["blue"])
co2_plot_by_country

st.pyplot(ggplot.draw(co2_plot_by_country))
st.subheader("Specific Data Point for Germany")


#Modify dataframe to just include top 10 emitting countries

#Create an ordered list of the top 10 emitting countries' names, top10
top10 = list(df_co2_plot_country.query("Year == 2014").sort_values(["Value"], ascending=False).iloc[:10,0])

#Create a new dataframe, df_top10, with only the top 10 emitting countries
is_in_df = df_co2_plot_country["Country"].isin(top10)
df_top10 = df_co2_plot_country[is_in_df].copy()

#Convert the values in the "Value" and "Year" columns into numeric format
df_top10["Value"] = pd.to_numeric(df_top10["Value"], errors = 'coerce')
df_top10["Year"] = pd.to_numeric(df_top10["Year"], errors = 'coerce')
df_top10

#idk why there are two values for some of the countries

#Plot top 10 emitting countries with different line colors
st.title("Top 10 Countries' CO2 Emissions")
last_pts = df_top10.query("Year == 2014")
top10_plot = (ggplot(data = df_top10, mapping =aes(x="Year", y="Value", color = "Country")) +
                    geom_line(show_legend = False) +
              scale_color_viridis(option="viridis")+
              scale_x_continuous(format = "d", expand = (0.30, 0))+
              scale_y_continuous(expand = (0.1, 0))+
                    labs(title = "Top 10 Emissions-producing Countries in 2014 (1900-2014)",
                         x="Year",
                y="Emissions (Metric Tons)",
                subtitle = "Limited to Reporting Countries") +
              geom_text_repel(
                  data=last_pts,
                  mapping = aes(x = "Year", y="Value", label="Country"),
                  show_legend = False,
                  check_overlap = True,
                  hjust = 0,
                  vjust = 0.5,
                  nudge_x = 10,
                  nudge_y = 100000,
                  force = 95,
                  nudge_unit = 'size'
              )
                   )
# top10_plot # This line was the cause of the error.

st.pyplot(ggplot.draw(top10_plot))

st.subheader("Top 10 Emitting Countries in 2014")
st.dataframe(last_pts.sort_values("Value", ascending=False).reset_index(drop=True))


#Turn the ascending countries list into a category list to sort the dataframe
#This is great for columns that have a certain number (10 in this case) of unique values
#but lots of repeated values.
st.title("Tile Plot of Top 10 CO2 Emissions")
st.write(
    "This application displays a tile plot showing the CO2 emissions for "
    "the top 10 emitting countries in 2014, with color intensity representing the log of the value."
)
df_top10_asc = df_top10.copy()
df_top10_asc["Country"] = pd.Categorical(
    df_top10_asc['Country'], # Use df_top10_asc here
    categories=top10,
    ordered=True)
df_top10_asc_sort = df_top10_asc.sort_values(by="Country")

#Create a "Log Value" column to use for the plot
df_top10_asc_sort["Log Value"] = np.log(df_top10_asc_sort['Value'])
df_top10_asc_sort = df_top10_asc_sort.query("Year >= 1900")
df_top10_asc_sort = df_top10_asc_sort.query("Indicator == 'Emissions'")

#Tile plot of top 10 emitting countries (lets_plot)
tile_plot = (ggplot(data = df_top10_asc_sort, mapping = aes(x="Year", y = "Country")) +
             geom_tile(aes(fill = "Log Value")) +
             scale_x_continuous(forma